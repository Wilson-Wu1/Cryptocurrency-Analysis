{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce6a6e31-f72d-4734-a929-542cbfad33a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-05\n",
      "2018-02-05\n",
      "True\n",
      "Empty DataFrame\n",
      "Columns: [date, SNo, Name, Symbol, High, Low, Open, Close, Volume, Marketcap, date_left, date_right, index, fear]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "import datetime \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def process_and_merge(fgIndex):\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "    \n",
    "   \n",
    "    fgIndex['date'] = pd.to_datetime(fgIndex['date'])\n",
    "    fgIndex['date'] = fgIndex['date'].dt.date\n",
    "    fgIndex = fgIndex.sort_values(by='date')\n",
    "    fgIndex = fgIndex.reset_index(level = None, drop = True)\n",
    "    print(fgIndex['date'][12])\n",
    "    \n",
    "    bit_info = pd.read_csv('coin_Bitcoin.csv', parse_dates=['Date'])    \n",
    "    bit_info['date'] = pd.to_datetime(bit_info['Date'])\n",
    "    mask = (bit_info['date'] > '2018-02-02')\n",
    "    bit_info = bit_info.loc[mask]\n",
    "    bit_info['date'] = bit_info['date'].dt.date\n",
    "    bit_info = bit_info.drop(['Date'], axis = 1)\n",
    "    bit_info = bit_info.reset_index(level = None, drop = True)\n",
    "    print(bit_info['date'][3])\n",
    "    \n",
    "    \n",
    "    joined_data = bit_info.join(fgIndex, on = \"date\", how = \"inner\", lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "    print(bit_info['date'][3] == fgIndex['date'][12])\n",
    "    print(joined_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "   # bit_info = bit_info.drop(['SNo', 'Name', 'Symbol'], axis=1)\n",
    "   # bit_info['Date'] = pd.to_datetime(bit_info['Date']).dt.date\n",
    "   # bit_info = bit_info.groupby('Date').sum()\n",
    "\n",
    "    #merging = daily_full.merge(bit_info, left_index=True, right_index=True)\n",
    "    \n",
    "   # return merging\n",
    "\n",
    "\n",
    "def run_model(df):\n",
    "\n",
    "    X = df.drop(['High', 'Low', 'Close'], axis=1)\n",
    "    y = df.Close\n",
    "    \n",
    "    # Test train split into the first 80% as our train, and last 20% for test\n",
    "    X_train = X.iloc[0:int(0.8*X.shape[0])]\n",
    "    X_valid = X.iloc[int(0.8*X.shape[0]):]\n",
    "    y_train = y.iloc[0:int(0.8*y.shape[0])]\n",
    "    y_valid = y.iloc[int(0.8*y.shape[0]):]\n",
    "\n",
    "    estimators = 300\n",
    "    depth = 7\n",
    "    split = 50\n",
    "\n",
    "    model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestRegressor(n_estimators=estimators,\n",
    "            max_depth=depth , min_samples_split=split, min_samples_leaf=15)\n",
    "        )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    # ONLY INCLUDE SCORE IN THE FINAL SUBMISSION\n",
    "    print(model.score(X_valid, y_valid))\n",
    "    print(model.score(X_train, y_train))\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    df = data_extract()\n",
    "    df = process_and_merge(df)\n",
    "    #run_model(df)\n",
    "    \n",
    "    \n",
    "if __name__== '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0796fd-b679-41ce-aa5e-c3c19d2fca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract():\n",
    "    response_API = requests.get('https://api.alternative.me/fng/?limit=0&format=csv')\n",
    "    data = response_API\n",
    "\n",
    "\n",
    "    dataset = data.text.splitlines()\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df = df.drop(df.index[0:4])\n",
    "    df.reset_index()\n",
    "    df = df.drop(df.index[1395:])\n",
    "\n",
    "    tmpDF = pd.DataFrame(columns=['date','index', 'fear'])\n",
    "    tmpDF[['date','index','fear']] = df[0].str.split(',',expand=True)\n",
    "    return tmpDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f9392-a4f6-45fb-b2e1-03088bfa6ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
